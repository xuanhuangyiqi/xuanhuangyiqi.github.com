<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: consistent | Htedsv Backyard]]></title>
  <link href="http://xuanhuangyiqi.github.io/blog/categories/consistent/atom.xml" rel="self"/>
  <link href="http://xuanhuangyiqi.github.io/"/>
  <updated>2016-09-15T20:02:20+02:00</updated>
  <id>http://xuanhuangyiqi.github.io/</id>
  <author>
    <name><![CDATA[htedsv]]></name>
    <email><![CDATA[xuanhuangyiqi@126.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Angluin-Learning-Algorithm]]></title>
    <link href="http://xuanhuangyiqi.github.io/blog/2014/08/15/anluin-learning-algorithm/"/>
    <updated>2014-08-15T20:24:10+02:00</updated>
    <id>http://xuanhuangyiqi.github.io/blog/2014/08/15/anluin-learning-algorithm</id>
    <content type="html"><![CDATA[<p>前两天在知乎回答了一个关于<a href="http://www.zhihu.com/question/24824487/answer/29196253">识别某种特定语言的方法</a>，根据这两天0赞同的情况，不禁让我对知户上计算机从业者的基础理论水平深表怀疑，不过当我看到第一名的答案时确实非常激动，因为一下子想起了2年前在知乎实习时为了识别某个语言，发现用正则表达式可能会非常麻烦，于是写了个自动机，当时刚刚从编译课上学了些自动机的原理，并且第一次正式尝试用它来解决实际遇到的问题，自然是非常激动，而第一名的方法也正是通过构造自动机来生成正则表达式。</p>

<p>不过在那之后，“自动机”与“编译”在我脑中基本成为两个非常相似的概念。我因为自动机的神奇而对编译中各种文法以及编译器的实现产生了兴趣。自认为目前做过最NB的一件事也于此相关——在看过龙书第一章，并且学习了推到规则之后，自己动手写了个简单的编译器作为大作业，不过大作业并没有因此得到满分，因为理论的欠缺，我甚至分不清lexical和syntax之间的区别，自认为高明的把词法分析、语法分析写在一起，并且跳过符号表；这些都被老师当成了扣分点。</p>

<!--more-->

<p>知道来到RWTH，一学期同时学了自动机与编译原理，才渐渐认识到两种理论其实各自自成体系，交集并没我想象的那么多。重学一边编译的过程从理论方面并没有给我更多的收获，这也让我第一次感觉本科上的课也不是都那么水，但是每周的作业中都包含编程题，也就是实现一个语言的一部分代码，当然这部分都是每周课上新学的，从词法分析，到LL(1)、LR(0)、SLR(1)、LR(1)一直到最后的语义分析和生成代码部分。相比于自己实现，这种方法显然更加“德国”，减少了像我一样“误入歧途”的风险。因为从这个过程中确实学到了很多编译器更规范的做法。</p>

<p>不过相比于编译原理，我从应用自动机课上收获的东西更多，以至于很多东西对我的世界观产生了很大影响，具体的很多想法以后在慢慢谈。今天就来说个具体的，也就是我认为这门课最正统，也是最NB的算法——Angluin’s Learning Algorithm。在回答问题之前我也把<a href="https://github.com/xuanhuangyiqi/AnluinLearning">项目</a>地址贴了上去。除了一些简单的介绍外，我今天想着重介绍下Angluin’s Learning Algorithm的核心：封闭性与一致性。不过在此之前，我还是要说，这个算法不是机器学习算法，不涉及概率，或者说每一步都是为了达到一个严谨的稳定状态。在混沌的世界，机器学习可以解决“一切”问题。这种说法是要表达：对于现实世界，机器学习因为对问题本身要求更低，所以解决问题的范围更广（因此看似神奇），然而也正因为其规律并不能适用所有，所以解决的效果无法达到完美。然而在理想化的形式世界，所有的问题都被抽象，形式化，虽然和现实脱离，但是却能在形式化的世界得到完美解决。下面就要正式介绍一下两个性质：</p>

<p>根据我在回答中的一些简单描述，大概可以把该算法解释为：<strong>通过反复询问新的词是否属于该语言来维护一个观测表的封闭性与一致性。</strong></p>

<h2 id="section">封闭性</h2>

<p>对于有两个词w,v 属于语言L，如果它们后面无论接什么词，都是要么同时属于L，要么同时不属于L，那么可以说这两个词的等价的，如果把他们放到自动机上面从初始状态开始跑一下，它们会停在同一个状态，那么这两个词就是等价的，比如对于正则语言(12)*，12和1212还有121212是互相等价的，1和121也是等价的。然而为了说明两个词的等价，我们并不一定需要找到所有词接在他们后面来验证他们是否属于这一语言，只需要几个有代表性的就够了，而要接的词也就是S集合（具体原因稍后再说），<strong>而R集合中的每一个词都可以根据后接S中的每一个词是否属于语言L来代表一个DFA上的状态</strong>，如果R中两个词w, v它们后接S中的每一个词都是要么同时属于L，要么同时不属于L，那么显然他们是等价的。如果我观测到有一个词R中的词w后接某个字母a之后不在R中，并且和R集合中的任意一个词都不等价，那么目前的DFA是不封闭的，说明wa代表了一个自动机上的新状态，那么通过R中加入wa来维护这个自动机的封闭性。</p>

<h2 id="section-1">一致性</h2>

<p>前面提到了两个词w, v等价的条件，并且我们认为S集合可以代表全集，来验证任意两个词的等价性，然而S集合虽然表面上R中的每个词是否等价区分开了，但其实可能是因为S集合不够大，并没有真正把两个不等价的词区分开，比如从现有S集合来判断，w~v（表示两者等价）。然而如果发现对于某个字母a，wa与va通过S来区分时并不等价，即对于S中的某个词s，was与vas并不是同时属于L，那么显然w和v也并不是真的等价，而区分它们的词正是as，所以通过给S添加元素as来维持自动机的一致性。</p>

<p>好了，虽然算法还有很多小问题值得思考与证明，比如知乎回答下vczh提的问题，但是最核心的东西应该是说清楚了，细节可以以后慢慢讨论。</p>
]]></content>
  </entry>
  
</feed>
